---
title: External Services
description: External services for Onlook
---

# External Services

Onlook requires several external services to provide its features. Each of these services is self-hostable under Apache 2.0 or equivalently permissive licenses.

## Self-hosting External Services

For assistance with self-hosting these services, please contact us at [founders@onlook.com](mailto:founders@onlook.com).

### 1. Supabase
- For scalable deployments, follow the official [Supabase self-hosting guide](https://supabase.com/docs/guides/self-hosting/docker) to deploy with Docker. 
- For single-machine deployments, you can run supabase through the CLI using the [single-machine guide](/self-hosting/single-machine#3-start-backend-services).

### 2. Sandbox Providers
- For scalable deployments, deploy E2B to GCP using their [self-hosting guide](https://github.com/e2b-dev/infra/blob/main/self-host.md).
- For single-machine deployments, we are adding a fully local sandbox provider in the future.

### 3. AI Providers
To configure custom AI providers:
1. Update the providers in [`packages/ai/src/chat/providers.ts`](https://github.com/onlook-dev/onlook/blob/main/packages/ai/src/chat/providers.ts). We already support Anthropic and OpenRouter as examples. You can follow the same format to add a new provider.
2. Update the usages by searching for [`initModel`](https://github.com/search?q=repo%3Aonlook-dev%2Fonlook+%22await+initModel%22&type=code)
3. Update your API keys in the `apps/web/client/.env` file to the provider's expected API keys.

Note: We support any provider from the [AI SDK providers](https://ai-sdk.dev/providers/ai-sdk-providers). You can add a custom provider by following these AI SDK provider guides: [OpenAI compatible](https://ai-sdk.dev/providers/openai-compatible-providers/custom-providers) and [Community](https://ai-sdk.dev/providers/community-providers/custom-providers).
